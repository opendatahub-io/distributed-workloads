accelerate==0.31.0
awscliv2==2.3.0
datasets==2.19.2
deepspeed==0.14.4
# Flash Attention 2 requires PyTorch to be installed first
# See https://github.com/Dao-AILab/flash-attention/issues/453
#flash-attn==2.5.9.post1
https://github.com/Dao-AILab/flash-attention/releases/download/v2.5.9.post1/flash_attn-2.5.9.post1+cu122torch2.3cxx11abiFALSE-cp39-cp39-linux_x86_64.whl
peft==0.11.1
ray[train]==2.23.0
torch==2.3.1
transformers==4.41.2
