accelerate==0.31.0
awscliv2==2.3.0
datasets==2.19.2
deepspeed==0.14.4
# Flash Attention 2 requires PyTorch to be installed first
# See https://github.com/Dao-AILab/flash-attention/issues/453
https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.3cxx11abiFALSE-cp39-cp39-linux_x86_64.whl
peft==0.11.1
ray[train]==2.23.0
torch==2.3.1
transformers==4.44.0
