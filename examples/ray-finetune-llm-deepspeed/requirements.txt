accelerate==0.31.0
awscliv2==2.3.0
datasets==2.19.2
deepspeed==0.14.3
# Flash Attention 2 requires PyTorch to be installed first
# See https://github.com/Dao-AILab/flash-attention/issues/246
flash-attn==2.5.9.post1
peft==0.11.1
ray[train]==2.23.0
torch==2.3.1
transformers==4.41.2
