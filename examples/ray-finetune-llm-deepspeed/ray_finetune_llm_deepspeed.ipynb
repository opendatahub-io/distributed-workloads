{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "204a90fb-da94-426a-8c0c-3a0c61b01086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from codeflare_sdk.cluster.cluster import Cluster, ClusterConfiguration\n",
    "from codeflare_sdk.cluster.auth import TokenAuthentication\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30c26b-d439-4d74-b3fe-d9e84db29a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the training and evaluation datasets.\n",
    "# This can be run only once.\n",
    "!{sys.executable} -m pip install datasets\n",
    "import create_dataset\n",
    "create_dataset.gsm8k_qa_no_tokens_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440b98a3-8ed3-4072-9cc2-763d0e6c6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate the CodeFlare SDK\n",
    "# On OpenShift, you can retrieve the token by running `oc whoami -t`,\n",
    "# and the server with `oc cluster-info`.\n",
    "auth = TokenAuthentication(\n",
    "    token = '',\n",
    "    server = '',\n",
    "    skip_tls=False\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d340f86-1a04-48d3-a5e7-067faecfc17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Ray cluster\n",
    "cluster = Cluster(ClusterConfiguration(\n",
    "    name='ray',\n",
    "    namespace='ray-finetune-llm-deepspeed',\n",
    "    num_workers=7,\n",
    "    worker_cpu_requests=16,\n",
    "    worker_cpu_limits=16,\n",
    "    head_cpu_requests=16,\n",
    "    head_cpu_limits=16,\n",
    "    worker_memory_requests=128,\n",
    "    worker_memory_limits=256,\n",
    "    head_memory_requests=128,\n",
    "    head_memory_limits=256,\n",
    "    # Use the following parameters with NVIDIA GPUs\n",
    "    # Ensure the Python version in the notebook image matches the version used in the Ray cluster to avoid compatibility issues\n",
    "    image=\"quay.io/rhoai/ray:2.35.0-py311-cu121-torch24-fa26\",\n",
    "    head_extended_resource_requests={'nvidia.com/gpu':1},\n",
    "    worker_extended_resource_requests={'nvidia.com/gpu':1},\n",
    "    # Or replace them with these parameters for AMD GPUs\n",
    "    # image=\"quay.io/rhoai/ray:2.35.0-py311-rocm61-torch24-fa26\",\n",
    "    # head_extended_resource_requests={'amd.com/gpu':1},\n",
    "    # worker_extended_resource_requests={'amd.com/gpu':1},\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cee11013-8646-4cda-94a2-f8e731baa1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Ray cluster\n",
    "cluster.up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a09df-3871-4791-9763-5dcdc081bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccda92-a0f0-4845-a13c-6aa735e75d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb29e733-eac5-4f3d-bbfa-543e8ee7fd1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Job Submission Client\n",
    "client = cluster.job_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The S3 bucket where to store checkpoint.\n",
    "# It can be set manually, otherwise it's retrieved from configured the data connection.\n",
    "s3_bucket = ''\n",
    "if not s3_bucket:\n",
    "    s3_bucket = os.environ.get('AWS_S3_BUCKET')\n",
    "assert s3_bucket, \"An S3 bucket must be provided to store checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2be5d8-66c7-46e2-ba3b-fa2f8a03b27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_id = client.submit_job(\n",
    "    entrypoint=\"python ray_finetune_llm_deepspeed.py \"\n",
    "               \"--model-name=meta-llama/Meta-Llama-3.1-8B \"\n",
    "               \"--lora \"\n",
    "               \"--num-devices=8 \"\n",
    "               \"--num-epochs=3 \"\n",
    "               \"--ds-config=./deepspeed_configs/zero_3_offload_optim_param.json \"\n",
    "               f\"--storage-path=s3://{s3_bucket}/ray_finetune_llm_deepspeed/ \"\n",
    "               \"--batch-size-per-device=32 \"\n",
    "               \"--eval-batch-size-per-device=32 \",\n",
    "    runtime_env={\n",
    "        \"env_vars\": {\n",
    "            'AWS_ACCESS_KEY_ID': os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "            'AWS_SECRET_ACCESS_KEY': os.environ.get('AWS_SECRET_ACCESS_KEY'),\n",
    "            'AWS_DEFAULT_REGION': os.environ.get('AWS_DEFAULT_REGION')\n",
    "        },\n",
    "        'pip': 'requirements.txt',\n",
    "        'working_dir': './',\n",
    "        \"excludes\": [\"/docs/\", \"*.ipynb\", \"*.md\"]\n",
    "    },\n",
    ")\n",
    "print(submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476f19b-1d51-44f5-8889-c5b01ed36343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.stop_job(submission_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f456f161-5122-4057-a5ac-f7f6b38651ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
