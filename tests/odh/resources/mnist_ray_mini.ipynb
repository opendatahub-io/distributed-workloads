{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55bc3ea-4ce3-49bf-bb1f-e209de8ca47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# Import pieces from codeflare-sdk\n",
    "from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication\n",
    "from codeflare_sdk.ray.client import RayJobClient\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show codeflare-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30888aed",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "namespace = \"default\"\n",
    "ray_image = \"has to be specified\"\n",
    "openshift_api_url = \"has to be specified\"\n",
    "kubernetes_user_bearer_token = \"has to be specified\"\n",
    "num_gpus = \"has to be specified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0538160",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = TokenAuthentication(\n",
    "    token=kubernetes_user_bearer_token,\n",
    "    server=openshift_api_url,\n",
    "    skip_tls=True,\n",
    ")\n",
    "auth.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bc870-091f-4e11-9642-cba145710159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create our cluster\n",
    "cluster = Cluster(\n",
    "    ClusterConfiguration(\n",
    "        namespace=namespace,\n",
    "        name='mnisttest',\n",
    "        head_cpu_requests=2,\n",
    "        head_cpu_limits=2,\n",
    "        head_memory_requests=6,\n",
    "        head_memory_limits=8,\n",
    "        head_extended_resource_requests={'nvidia.com/gpu':0},\n",
    "        num_workers=1,\n",
    "        worker_cpu_requests=1,\n",
    "        worker_cpu_limits=1,\n",
    "        worker_memory_requests=1,\n",
    "        worker_memory_limits=4,\n",
    "        worker_extended_resource_requests={'nvidia.com/gpu':int(num_gpus)},\n",
    "        image=ray_image,\n",
    "        write_to_file=True,\n",
    "        verify_tls=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = os.path.expanduser(\"~/.codeflare/resources/\")\n",
    "outfile = os.path.join(directory_path, \"mnisttest.yaml\")\n",
    "cluster_yaml = None\n",
    "with open(outfile) as f:\n",
    "    cluster_yaml = yaml.load(f, yaml.FullLoader)\n",
    "\n",
    "# Add toleration for GPU nodes to Ray cluster worker pod\n",
    "cluster_yaml[\"spec\"][\"workerGroupSpecs\"][0][\"template\"][\"spec\"][\"tolerations\"]=[{\"key\": \"nvidia.com/gpu\", \"value\": \"NONE\", \"effect\": \"NoSchedule\"}]\n",
    "\n",
    "with open(outfile, \"w\") as f:\n",
    "    yaml.dump(cluster_yaml, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0884bbc-c224-4ca0-98a0-02dfa09c2200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bring up the cluster\n",
    "cluster.up()\n",
    "# Wait until status is updated (skip dashboard check as route naming changed in kuberay operator)\n",
    "cluster.wait_ready(dashboard_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71c1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd45bc5-03c0-4ae5-9ec5-dd1c30f1a084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access dashboard directly via internal service (notebook runs inside the cluster)\n",
    "# The service mnisttest-head-svc exposes the Ray dashboard on port 8265\n",
    "ray_dashboard = f\"http://mnisttest-head-svc.{namespace}.svc.cluster.local:8265\"\n",
    "print(f\"Ray dashboard URL: {ray_dashboard}\")\n",
    "\n",
    "header = {\"Authorization\": f\"Bearer {kubernetes_user_bearer_token}\"}\n",
    "ray_client = RayJobClient(address=ray_dashboard, headers=header, verify=False)\n",
    "\n",
    "submission_id = ray_client.submit_job(\n",
    "    entrypoint=\"python mnist.py\",\n",
    "    runtime_env={\n",
    "        \"env_vars\": {\n",
    "            \"NCCL_DEBUG\": \"INFO\",\n",
    "            \"PIP_INDEX_URL\":os.environ.get(\"PIP_INDEX_URL\"),\n",
    "            \"PIP_TRUSTED_HOST\":os.environ.get(\"PIP_TRUSTED_HOST\"),\n",
    "        },\n",
    "        \"working_dir\": \"/opt/app-root/notebooks/..data\",\n",
    "        \"pip\": \"/opt/app-root/notebooks/requirements.txt\",\n",
    "    },\n",
    "    entrypoint_num_gpus=num_gpus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63a178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "status = None\n",
    "error_count = 0\n",
    "max_errors = 60  # Max consecutive errors before giving up\n",
    "\n",
    "while status != \"SUCCEEDED\":\n",
    "    sleep(1)\n",
    "    try:\n",
    "        status = ray_client.get_job_status(submission_id)\n",
    "        error_count = 0  # Reset on success\n",
    "        print(f\"Job status: {status}\")\n",
    "        if status == \"FAILED\":\n",
    "            print(\"Job failed!\")\n",
    "            break\n",
    "    except (RuntimeError, requests.exceptions.ConnectionError, ConnectionError) as e:\n",
    "        error_count += 1\n",
    "        print(f\"Transient error ({error_count}/{max_errors}) checking job status: {type(e).__name__}: {e}\")\n",
    "        if error_count >= max_errors:\n",
    "            print(f\"Too many consecutive errors, giving up\")\n",
    "            break\n",
    "        continue\n",
    "\n",
    "if status == \"SUCCEEDED\":\n",
    "    print(\"Job completed Successfully !\")\n",
    "else:\n",
    "    print(f\"Job did not succeed. Final status: {status}\")\n",
    "\n",
    "sleep(10) # Brief pause before cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b099777",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.down()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
